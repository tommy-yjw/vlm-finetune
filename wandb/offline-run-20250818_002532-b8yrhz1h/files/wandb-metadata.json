{
  "os": "Linux-5.4.0-42-generic-x86_64-with-glibc2.35",
  "python": "CPython 3.11.3",
  "startedAt": "2025-08-17T16:25:33.034420Z",
  "args": [
    "--local_rank=0",
    "--deepspeed",
    "./configs/deepspeed_config.json",
    "--model_name_or_path",
    "/data/oceanus_ctr/j-yanjiangwei-jk/.cache/modelscope/hub/models/Qwen/Qwen2.5-VL-7B-Instruct",
    "--output_dir",
    "./output/qwen_lora_llm_full_vit",
    "--tuning_strategy",
    "lora_llm_full_vit",
    "--dataset_config_path",
    "./configs/dataset_config.json",
    "--dataset_names",
    "360_aigc_layout",
    "fix_direction",
    "CGL",
    "PKU",
    "--min_pixels",
    "200704",
    "--max_pixels",
    "4005632",
    "--train_split_ratio",
    "0.9",
    "--epochs",
    "4",
    "--per_device_train_batch_size",
    "1",
    "--gradient_accumulation_steps",
    "16",
    "--num_workers",
    "16",
    "--learning_rate_llm",
    "5e-6",
    "--learning_rate_vit",
    "1e-5",
    "--learning_rate_projector",
    "1e-5",
    "--max_seq_length",
    "2048",
    "--temperature",
    "0.3",
    "--top_p",
    "0.9",
    "--top_k",
    "3",
    "--use_wandb",
    "--wandb_project",
    "qwen-vl-finetune",
    "--wandb_run_name",
    "full-finetune-run",
    "--log_to_file"
  ],
  "program": "/data/oceanus_ctr/j-yanjiangwei-jk/vlm-finetune/train.py",
  "codePath": "train.py",
  "git": {
    "remote": "https://github.com/tommy-yjw/vlm-finetune.git",
    "commit": "c65b0e6d92c5644ff7eb74ddbcc5d770596f14b5"
  },
  "root": "/data/oceanus_ctr/j-yanjiangwei-jk/vlm-finetune",
  "host": "cv-a800-dev01-temp",
  "executable": "/data/oceanus_ctr/j-yanjiangwei-jk/.conda/envs/qwenpt/bin/python",
  "codePathLocal": "train.py",
  "cpu_count": 64,
  "cpu_count_logical": 15,
  "gpu": "NVIDIA A800-SXM4-80GB",
  "gpu_count": 1,
  "disk": {
    "/": {
      "total": "3838878167040",
      "used": "442895466496"
    }
  },
  "memory": {
    "total": "128849018880"
  },
  "cpu": {
    "count": 64,
    "countLogical": 15
  },
  "gpu_nvidia": [
    {
      "name": "NVIDIA A800-SXM4-80GB",
      "memoryTotal": "85899345920",
      "cudaCores": 6912,
      "architecture": "Ampere"
    }
  ],
  "cudaVersion": "12.4"
}